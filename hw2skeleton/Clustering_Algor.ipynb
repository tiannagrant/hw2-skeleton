{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some utility classes to represent a PDB structure\n",
    "\n",
    "class Atom:\n",
    "    \"\"\"\n",
    "    A simple class for an amino acid residue\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, type):\n",
    "        self.type = type\n",
    "        self.coords = (0.0, 0.0, 0.0)\n",
    "\n",
    "    # Overload the __repr__ operator to make printing simpler.\n",
    "    def __repr__(self):\n",
    "        return self.type\n",
    "\n",
    "class Residue:\n",
    "    \"\"\"\n",
    "    A simple class for an amino acid residue\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, type, number):\n",
    "        self.type = type\n",
    "        self.number = number\n",
    "        self.atoms = []\n",
    "\n",
    "    # Overload the __repr__ operator to make printing simpler.\n",
    "    def __repr__(self):\n",
    "        return \"{0} {1}\".format(self.type, self.number)\n",
    "\n",
    "class ActiveSite:\n",
    "    \"\"\"\n",
    "    A simple class for an active site\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.residues = []\n",
    "\n",
    "    # Overload the __repr__ operator to make printing simpler.\n",
    "    def __repr__(self):\n",
    "        return self.name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "def read_active_sites(dir):\n",
    "    \"\"\"\n",
    "    Read in all of the active sites from the given directory.\n",
    "\n",
    "    Input: directory\n",
    "    Output: list of ActiveSite instances\n",
    "    \"\"\"\n",
    "    files = glob.glob(dir + '/*.pdb')\n",
    "\n",
    "    active_sites = []\n",
    "    # iterate over each .pdb file in the given directory\n",
    "    for filepath in glob.iglob(os.path.join(dir, \"*.pdb\")):\n",
    "\n",
    "        active_sites.append(read_active_site(filepath))\n",
    "\n",
    "    print(\"Read in %d active sites\"%len(active_sites))\n",
    "\n",
    "    return active_sites\n",
    "\n",
    "\n",
    "def read_active_site(filepath):\n",
    "    \"\"\"\n",
    "    Read in a single active site given a PDB file\n",
    "\n",
    "    Input: PDB file path\n",
    "    Output: ActiveSite instance\n",
    "    \"\"\"\n",
    "    basename = os.path.basename(filepath)\n",
    "    name = os.path.splitext(basename)\n",
    "\n",
    "    if name[1] != \".pdb\":\n",
    "        raise IOError(\"%s is not a PDB file\"%filepath)\n",
    "\n",
    "    active_site = ActiveSite(name[0])\n",
    "\n",
    "    r_num = 0\n",
    "\n",
    "    # open pdb file\n",
    "    with open(filepath, \"r\") as f:\n",
    "        # iterate over each line in the file\n",
    "        for line in f:\n",
    "            if line[0:3] != 'TER':\n",
    "                # read in an atom\n",
    "                atom_type = line[13:17].strip()\n",
    "                x_coord = float(line[30:38])\n",
    "                y_coord = float(line[38:46])\n",
    "                z_coord = float(line[46:54])\n",
    "                atom = Atom(atom_type)\n",
    "                atom.coords = (x_coord, y_coord, z_coord)\n",
    "\n",
    "                residue_type = line[17:20]\n",
    "                residue_number = int(line[23:26])\n",
    "\n",
    "                # make a new residue if needed\n",
    "                if residue_number != r_num:\n",
    "                    residue = Residue(residue_type, residue_number)\n",
    "                    r_num = residue_number\n",
    "\n",
    "                # add the atom to the residue\n",
    "                residue.atoms.append(atom)\n",
    "\n",
    "            else:  # I've reached a TER card\n",
    "                active_site.residues.append(residue)\n",
    "\n",
    "    return active_site\n",
    "\n",
    "\n",
    "def write_clustering(filename, clusters):\n",
    "    \"\"\"\n",
    "    Write the clustered ActiveSite instances out to a file.\n",
    "\n",
    "    Input: a filename and a clustering of ActiveSite instances\n",
    "    Output: none\n",
    "    \"\"\"\n",
    "\n",
    "    out = open(filename, 'w')\n",
    "\n",
    "    for i in range(len(clusters)):\n",
    "        out.write(\"\\nCluster %d\\n--------------\\n\" % i)\n",
    "        for j in range(len(clusters[i])):\n",
    "            out.write(\"%s\\n\" % clusters[i][j])\n",
    "\n",
    "    out.close()\n",
    "\n",
    "\n",
    "def write_mult_clusterings(filename, clusterings):\n",
    "    \"\"\"\n",
    "    Write a series of clusterings of ActiveSite instances out to a file.\n",
    "\n",
    "    Input: a filename and a list of clusterings of ActiveSite instances\n",
    "    Output: none\n",
    "    \"\"\"\n",
    "\n",
    "    out = open(filename, 'w')\n",
    "\n",
    "    for i in range(len(clusterings)):\n",
    "        clusters = clusterings[i]\n",
    "\n",
    "        for j in range(len(clusters)):\n",
    "            out.write(\"\\nCluster %d\\n------------\\n\" % j)\n",
    "            for k in range(len(clusters[j])):\n",
    "                out.write(\"%s\\n\" % clusters[j][k])\n",
    "\n",
    "    out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_path=\"/Users/student/Documents/hw2-skeleton/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in 136 active sites\n"
     ]
    }
   ],
   "source": [
    "# this defintion read the entire data\n",
    "test=read_active_sites(example_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "first=test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46495"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'46495'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ASP 165, ASP 167, SER 211, ARG 213, ASP 254, LYS 258, ASP 278]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first.residues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[N, CA, C, O, CB, CG, OD1, OD2]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first.residues[0].atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first.residues[0].atoms[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41.692, 10.964, 19.961)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first.residues[0].atoms[0].coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_coordinates(PDB):\n",
    "    residues_list=[]\n",
    "    atoms_list=[]\n",
    "    for residue in PDB.residues:\n",
    "        if residue == ['CA','N','C','CB']:\n",
    "            residues_list.append(residue)\n",
    "        for atoms in residue.atoms:\n",
    "            atoms_list.append(atoms.coords)\n",
    "            \n",
    "    return atoms_list\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the backbone coordinate list into a dataframe: \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "def convert_dataframe(List):\n",
    "    backbone_coordinates = pd.DataFrame(np.array(List).reshape(len(List),3), columns = list(\"xyz\"))\n",
    "    return(backbone_coordinates)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_active_sites(test):\n",
    "    for i in test:\n",
    "        example_list=avg_coordinates(i)\n",
    "        convert = convert_dataframe(example_list)\n",
    "        one_active_site=pd.DataFrame(convert.mean(),columns=[i.name]).T\n",
    "        yield one_active_site\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_of_all_activesites = pd.concat(list(all_active_sites(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>46495</td>\n",
       "      <td>43.935672</td>\n",
       "      <td>14.163776</td>\n",
       "      <td>25.155793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23812</td>\n",
       "      <td>97.470347</td>\n",
       "      <td>49.718286</td>\n",
       "      <td>26.240388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41729</td>\n",
       "      <td>21.226330</td>\n",
       "      <td>36.436375</td>\n",
       "      <td>12.912402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91911</td>\n",
       "      <td>-0.426087</td>\n",
       "      <td>-0.153887</td>\n",
       "      <td>36.409313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82212</td>\n",
       "      <td>60.954000</td>\n",
       "      <td>12.616917</td>\n",
       "      <td>48.877250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               x          y          z\n",
       "46495  43.935672  14.163776  25.155793\n",
       "23812  97.470347  49.718286  26.240388\n",
       "41729  21.226330  36.436375  12.912402\n",
       "91911  -0.426087  -0.153887  36.409313\n",
       "82212  60.954000  12.616917  48.877250"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_of_all_activesites.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_array=np.array(mean_of_all_activesites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mean_of_all_activesites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Caculating euclidean distance by pairwise: using scipy.spatial distance\n",
    "from scipy.spatial import distance\n",
    "\n",
    "#Y = distance.pdist(new_array, 'euclidean')\n",
    "Y = distance.squareform(distance.pdist(new_array, 'euclidean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.        ,  64.2748854 ,  34.0834787 , ...,  19.7028291 ,\n",
       "         78.83148657, 159.45596423],\n",
       "       [ 64.2748854 ,   0.        ,  78.53148685, ...,  83.04319709,\n",
       "         86.82621058, 215.35110349],\n",
       "       [ 34.0834787 ,  78.53148685,   0.        , ...,  40.04646147,\n",
       "         71.69224029, 160.129774  ],\n",
       "       ...,\n",
       "       [ 19.7028291 ,  83.04319709,  40.04646147, ...,   0.        ,\n",
       "         91.75320237, 141.24777578],\n",
       "       [ 78.83148657,  86.82621058,  71.69224029, ...,  91.75320237,\n",
       "          0.        , 223.92258778],\n",
       "       [159.45596423, 215.35110349, 160.129774  , ..., 141.24777578,\n",
       "        223.92258778,   0.        ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import KMeans\n",
    "mimport scipy.cluster.hierarchy as sch\n",
    "        model = AgglomerativeClustering(n_clusters=5, affinity='euclidean', linkage='ward')\n",
    "        model.fit(X)\n",
    "        labels = model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "#Agglomerative hierarchical clustering \n",
    "def k_means(new_array,K):\n",
    "        nrow = new_array.shape[0]\n",
    "        ncol = new_array.shape[1]\n",
    "        \n",
    "        # pick K random data points as intital centroids\n",
    "        initial_centriods = np.random.choice(nrow, K, replace=False)\n",
    "        centeroids = new_array[initial_centroids]\n",
    "        centroids_old = np.zeros[K, ncol]\n",
    "        cluster_assignments = np.zeros(nrows)\n",
    "        while (centroids_old != centeroids).any():\n",
    "            centeroids_old.append(centeroids)\n",
    "            #compute the distances between data points and the centeriods \n",
    "            dist_matrix = distance_matrix(new_array, centeroids, p=2)\n",
    "            #find closest centeroid\n",
    "            for i in np.arrange(nrow): \n",
    "                d=dist_matrix[i]\n",
    "                closest_centeroid = (np.where(d == np.min(d)))[0][0]\n",
    "            #associate data points with closest centeriod\n",
    "            cluster_assignments[i] = closest_centeroid\n",
    "            #recompute centeriods\n",
    "            for k in np.arange[K]:\n",
    "                new_array_k = new_array[cluster_assignments==k]\n",
    "                centeroids[k] = np.apply_along_axis(np.mean, axis=0, arr=new_array_k)\n",
    "        return(centeroids, cluster_assignments)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K Means Clustering \n",
    "#Randomly intitalize two data points called the center centeroids\n",
    "#Use Euclidean distacne to find what data point is closest to the centeroids\n",
    "#Based on the distance from c1 and c2 centeroids, the data point will be grouped into clusters\n",
    "#Compute the datapoints of the centeroid inside cluster 1 \n",
    "#Repostion the centeroid of the cluster 1 to the new centeroid\n",
    "#Compute the centeroid of datapoints inside cluster 2\n",
    "#Reposition the centeroid of cluster 2 to the new centeroid \n",
    "#Repeat the calculation of centeroids and repostioning until none of the cluster assignments change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The similiarity metric I used is called Euclidean distance: I used it because to assign data points to a centeroid I needed a proximity measurement. \n",
    "#Euclidean was the best option for me biologically because I can see if the backbone coordinates align, are the same close in distance. \n",
    "#In the end when thinking about using the backbone coordinates as a way to measure similarity in active site. \n",
    "#This was a decision biologically. biologically it would be hard to overlapped coordinates because all the active sites are not the same length in atoms. \n",
    "#For future directions it would be better if I chose either amino acid count or a count postive, negative , hydrophobic phenotype. These measurements would be more informative biologically. \n",
    "#I chose K-means clustering\n",
    "#I chose agglomerative hierarchical clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
